{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23fec28",
   "metadata": {},
   "source": [
    "\n",
    "# 01 â€” Clean pipeline (SWAPâ€‘SAFE): Data â†’ ALS â†’ Metrics â†’ MLflow\n",
    "\n",
    "This version is **robust** to the occasional factor **swap bug** in `implicit` (when item/user\n",
    "factor matrices get flipped). It also limits BLAS threads to avoid warnings/perf issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ce4cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: http://mlflow:5001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, io, zipfile, pathlib, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# BLAS/threading hygiene\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "try:\n",
    "    from threadpoolctl import threadpool_limits\n",
    "    threadpool_limits(1, \"blas\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Core libs\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "import mlflow\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69da94ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings: (100836, 4) movies: (9742, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ROOT = pathlib.Path(\"/workspace\")\n",
    "DATA = ROOT / \"data\" / \"raw\"\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "TARGET = DATA / \"ml-latest-small\"\n",
    "RATINGS_CSV = TARGET / \"ratings.csv\"\n",
    "MOVIES_CSV  = TARGET / \"movies.csv\"\n",
    "\n",
    "if not RATINGS_CSV.exists():\n",
    "    import requests\n",
    "    print(\"Downloading MovieLens (ml-latest-small)â€¦\")\n",
    "    z = zipfile.ZipFile(io.BytesIO(requests.get(URL, timeout=60).content))\n",
    "    z.extractall(DATA)\n",
    "\n",
    "ratings = pd.read_csv(RATINGS_CSV)\n",
    "movies  = pd.read_csv(MOVIES_CSV)\n",
    "\n",
    "print(\"ratings:\", ratings.shape, \"movies:\", movies.shape)\n",
    "ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9151a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI shape (users, items): (609, 6298) nnz: 48580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   user_index  userId\n",
       " 0           0       1\n",
       " 1           1       2\n",
       " 2           2       3\n",
       " 3           3       4\n",
       " 4           4       5,\n",
       "    item_index  movieId                               title\n",
       " 0           0        1                    Toy Story (1995)\n",
       " 1           1        2                      Jumanji (1995)\n",
       " 2           2        3             Grumpier Old Men (1995)\n",
       " 3           3        5  Father of the Bride Part II (1995)\n",
       " 4           4        6                         Heat (1995))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Positive-only implicit feedback\n",
    "pos = ratings[ratings[\"rating\"] >= 4.0][[\"userId\", \"movieId\"]].copy()\n",
    "pos[\"rating\"] = 1.0\n",
    "\n",
    "# Compact categorical mapping â†’ contiguous user/item indices\n",
    "u_cat = pos[\"userId\"].astype(\"category\")\n",
    "i_cat = pos[\"movieId\"].astype(\"category\")\n",
    "\n",
    "u_idx = u_cat.cat.codes.to_numpy()\n",
    "i_idx = i_cat.cat.codes.to_numpy()\n",
    "vals  = pos[\"rating\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "n_users = len(u_cat.cat.categories)\n",
    "n_items = len(i_cat.cat.categories)\n",
    "\n",
    "UI = csr_matrix((vals, (u_idx, i_idx)), shape=(n_users, n_items), dtype=np.float32)\n",
    "print(\"UI shape (users, items):\", UI.shape, \"nnz:\", UI.nnz)\n",
    "\n",
    "# Mapping tables (for API/UI)\n",
    "users_map = pd.DataFrame({\"user_index\": np.arange(n_users), \"userId\": u_cat.cat.categories.astype(int)})\n",
    "items_map = pd.DataFrame({\"item_index\": np.arange(n_items), \"movieId\": i_cat.cat.categories.astype(int)}).merge(\n",
    "    movies[[\"movieId\",\"title\"]], on=\"movieId\", how=\"left\"\n",
    ")\n",
    "users_map.head(), items_map.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c5a7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((609, 6298), 38864)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rows, cols = UI.nonzero()\n",
    "idx_all = np.arange(UI.nnz, dtype=np.int64)\n",
    "train_idx, test_idx = train_test_split(idx_all, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_sparse(indices):\n",
    "    r = rows[indices]; c = cols[indices]; v = UI.data[indices]\n",
    "    return csr_matrix((v, (r, c)), shape=UI.shape, dtype=np.float32)\n",
    "\n",
    "UI_train = build_sparse(train_idx)\n",
    "UI_test  = build_sparse(test_idx)\n",
    "\n",
    "UI_train_w = bm25_weight(UI_train, K1=1.2, B=0.75).astype(np.float32)\n",
    "UI_train_w.shape, UI_train_w.nnz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d451769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IU_train_w (items, users): (6298, 609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa6235d285c4deb9b14717f69fc4219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_factors: (609, 64)\n",
      "user_factors: (6298, 64)\n",
      "SWAPPED detected: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparams\n",
    "factors = 64\n",
    "regularization = 0.02\n",
    "iterations = 15\n",
    "k_eval = 10\n",
    "\n",
    "# Train on ITEMÃ—USER (transpose)\n",
    "IU_train_w = UI_train_w.T.tocsr()\n",
    "print(\"IU_train_w (items, users):\", IU_train_w.shape)\n",
    "\n",
    "model = AlternatingLeastSquares(\n",
    "    factors=factors,\n",
    "    regularization=regularization,\n",
    "    iterations=iterations,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(IU_train_w)\n",
    "\n",
    "# Shapes reported by model\n",
    "print(\"item_factors:\", model.item_factors.shape)\n",
    "print(\"user_factors:\", model.user_factors.shape)\n",
    "\n",
    "# Detect potential swap (rare implicit quirk)\n",
    "n_items_train = UI_train.shape[1]\n",
    "n_users_train = UI_train.shape[0]\n",
    "n_items_model, k1 = model.item_factors.shape\n",
    "n_users_model, k2 = model.user_factors.shape\n",
    "\n",
    "SWAPPED = (n_items_model == n_users_train) and (n_users_model == n_items_train)\n",
    "print(\"SWAPPED detected:\", SWAPPED)\n",
    "\n",
    "def get_items_matrix():\n",
    "    return model.user_factors if SWAPPED else model.item_factors\n",
    "\n",
    "def get_user_vec(u: int):\n",
    "    return model.item_factors[u] if SWAPPED else model.user_factors[u]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941213ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision_at_10': 0.1526, 'recall_at_10': 0.1578889390139475, 'map_at_10': 0.11149441861929957}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build truth from TEST and define popularity (from TRAIN)\n",
    "truth = defaultdict(set)\n",
    "t_rows, t_cols = UI_test.nonzero()\n",
    "for r, c in zip(t_rows, t_cols):\n",
    "    truth[r].add(c)\n",
    "\n",
    "pop_counts = np.asarray(UI_train.sum(axis=0)).ravel()\n",
    "pop_order = np.argsort(-pop_counts)\n",
    "\n",
    "def recommend_manual(u: int, N: int = 10) -> list[int]:\n",
    "    I = get_items_matrix()\n",
    "    n_items_eff = I.shape[0]\n",
    "\n",
    "    # Cold user in TRAIN â†’ popularity\n",
    "    if UI_train.getrow(u).nnz == 0:\n",
    "        return pop_order[:N].tolist()\n",
    "\n",
    "    # Dot-product scores\n",
    "    scores = I @ get_user_vec(u)\n",
    "    # Mask seen (clip to model's item range)\n",
    "    seen = [i for i in UI_train.getrow(u).indices if i < n_items_eff]\n",
    "    if seen:\n",
    "        scores[seen] = -1e12\n",
    "\n",
    "    top = np.argpartition(-scores, min(N, n_items_eff-1))[:N]\n",
    "    top = top[np.argsort(-scores[top])]\n",
    "    return top.tolist()\n",
    "\n",
    "def eval_at_k_manual(k: int = 10, sample_users: int = 500):\n",
    "    users = np.array(list(truth.keys()))\n",
    "    if len(users) > sample_users:\n",
    "        rng = np.random.default_rng(42)\n",
    "        users = rng.choice(users, size=sample_users, replace=False)\n",
    "\n",
    "    # Also clip TEST truth to model's item range\n",
    "    n_items_eff = get_items_matrix().shape[0]\n",
    "    clipped_truth = {u: {i for i in items if i < n_items_eff} for u, items in truth.items()}\n",
    "\n",
    "    precs, recs, maps = [], [], []\n",
    "    for u in users:\n",
    "        t = clipped_truth[u]\n",
    "        if not t:\n",
    "            continue\n",
    "        p = recommend_manual(u, N=k)\n",
    "        inter = len(set(p) & t)\n",
    "        precs.append(inter / k)                # Precision@k\n",
    "        recs.append(inter / len(t))            # Recall@k\n",
    "\n",
    "        hits, score = 0, 0.0                   # MAP@k\n",
    "        for rank, item in enumerate(p, start=1):\n",
    "            if item in t:\n",
    "                hits += 1\n",
    "                score += hits / rank\n",
    "        maps.append(score / min(k, len(t)))\n",
    "    return float(np.mean(precs)), float(np.mean(recs)), float(np.mean(maps))\n",
    "\n",
    "p_atk, r_atk, map_atk = eval_at_k_manual(k=k_eval, sample_users=500)\n",
    "print({\"precision_at_10\": p_atk, \"recall_at_10\": r_atk, \"map_at_10\": map_atk})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2cd77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ALS_swap_safe at: http://mlflow:5001/#/experiments/1/runs/1090ab7632f34bc88dc0c12154d32691\n",
      "ðŸ§ª View experiment at: http://mlflow:5001/#/experiments/1\n",
      "Artifacts saved to: /workspace/artifacts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save artifacts & Log to MLflow\n",
    "ART = ROOT / \"artifacts\"\n",
    "ART.mkdir(exist_ok=True)\n",
    "\n",
    "# Save swap-safe model (npz with factors)\n",
    "model_path = ART / \"als_model.npz\"\n",
    "np.savez_compressed(model_path, user_factors=model.user_factors, item_factors=model.item_factors)\n",
    "\n",
    "# Save mappings\n",
    "users_map_path = ART / \"users_map.csv\"\n",
    "items_map_path = ART / \"items_map.csv\"\n",
    "users_map.to_csv(users_map_path, index=False)\n",
    "items_map.to_csv(items_map_path, index=False)\n",
    "\n",
    "# Save config (including SWAPPED flag)\n",
    "config = {\n",
    "    \"model\": \"implicit_ALS\",\n",
    "    \"factors\": int(model.item_factors.shape[1]),\n",
    "    \"regularization\": regularization,\n",
    "    \"iterations\": iterations,\n",
    "    \"k_eval\": k_eval,\n",
    "    \"swapped_detected\": bool(SWAPPED),\n",
    "}\n",
    "config_path = ART / \"run_config.json\"\n",
    "config_path.write_text(json.dumps(config, indent=2))\n",
    "\n",
    "# Log to MLflow\n",
    "mlflow.set_experiment(\"netflix-poc\")\n",
    "with mlflow.start_run(run_name=\"ALS_swap_safe\"):\n",
    "    for k, v in config.items():\n",
    "        mlflow.log_param(k, v)\n",
    "    mlflow.log_metric(\"precision_at_10\", float(p_atk))\n",
    "    mlflow.log_metric(\"recall_at_10\", float(r_atk))\n",
    "    mlflow.log_metric(\"map_at_10\", float(map_atk))\n",
    "\n",
    "    mlflow.log_artifact(str(model_path))\n",
    "    mlflow.log_artifact(str(users_map_path))\n",
    "    mlflow.log_artifact(str(items_map_path))\n",
    "    mlflow.log_artifact(str(config_path))\n",
    "\n",
    "print(\"Artifacts saved to:\", ART)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c8ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample user index: 574\n",
      "Recommended titles:\n",
      "- Who Framed Roger Rabbit? (1988)\n",
      "- Poltergeist (1982)\n",
      "- There's Something About Mary (1998)\n",
      "- Ace Ventura: Pet Detective (1994)\n",
      "- Wallace & Gromit: The Wrong Trousers (1993)\n",
      "- Back to the Future (1985)\n",
      "- Ghostbusters (a.k.a. Ghost Busters) (1984)\n",
      "- Man on the Moon (1999)\n",
      "- As Good as It Gets (1997)\n",
      "- Doors, The (1991)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample recommendations (titles)\n",
    "rng = np.random.default_rng(7)\n",
    "sample_user = int(rng.choice(list(truth.keys())) if len(truth) else 0)\n",
    "recs_idx = recommend_manual(sample_user, N=10)\n",
    "\n",
    "ix = items_map.set_index(\"item_index\")\n",
    "titles = ix.loc[[i for i in recs_idx if i in ix.index]][\"title\"].fillna(\"(no title)\").tolist()\n",
    "\n",
    "print(\"Sample user index:\", sample_user)\n",
    "print(\"Recommended titles:\")\n",
    "for t in titles:\n",
    "    print(\"-\", t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
